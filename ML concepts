										HANDS-ON-MACHINE-LEARNING(Aurelien Geron)
									
30-9-20	
Day 1:	
                   Batch Learning - non incremental, restart
                   Online Learing - incremental ,on the fly ,mini batches
								
                               GENERALIZATION  
                   Instance-based Learning - adapting by similarity KNN
                   Model-based Learning - typical LinearRegression
                                   
                   Training Set, Validation Set, Test Set

01-10-20            
Day 2:		  
		   P.Metrics for Regressin - RMSE( outlier sensitive), MAE
		   Metrics for Classificatin - Precision(FP), Recall(FN)
		   f Beta, Accuracy_Score( Equal Distribution of Target Class)
									
		   Feature Normalization - Range of dataset 0 - 1
		   Feature Standardization - Dataset show Gaussian Distribution
								   
		   Gaussian Distribution - Bell Shaped Curve
		   1std = 68%, 2std = 95%, 3std = 99.7%

02-10-20
Day 3:
		   OrdinalImputer, One-Hot-Encoding
		   
		   K-Fold Cross Validation - Checking for Overfitting
		   
		   HypterParameter Tuning - GridSearchCV, RandomizedSearchCV
		   
03-10-20
Day 4:
		   Linear Regression -- The Normal Equation,
		   			Or
		   Gradient Descent - Batch GD, Stochastic SD, Mini-batch GD
		   
04-10-20
Day 5:
		  Polynomial Regression - MOre Feature with extra power( degree )
				Regularized Regression
		  Ridge Regression aka Squared penalty aka L2 norm - @*W**2 -- slope closer to 0
		  Lasso Regression aka Absolute penaly aka L1 norm - @*|W| -- slope could be 0
		  Elastic Net - Sum of Ridge( r=0 ) And Lasso Regression( r == 1 ) 
		  EarlyStopping - Stopping the training as soon as valid error reaches min
